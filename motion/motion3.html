<!doctype html>
<html lang="pl">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Frame differencing — RGB różne odstępy</title>
<style>
  body { font-family: system-ui, -apple-system, "Segoe UI", Roboto, Arial; padding: 16px; background:#111; color:#eee; }
  #controls { display:flex; flex-wrap:wrap; gap:12px; align-items:flex-start; margin-bottom:12px; }
  label { font-size:14px; }
  canvas { background:#000; border-radius:8px; box-shadow:0 6px 18px rgba(0,0,0,0.6); }
  #out { image-rendering: pixelated; }
  textarea { width:160px; height:80px; font-family:monospace; background:#222; color:#0f0; border-radius:6px; border:1px solid #333; padding:6px; resize:none; }
  small { color:#aaa; display:block; margin-top:6px; }
  .muted { color:#aaa; font-size:13px; }
</style>
</head>
<body>
<h2>Różnicowanie klatek — różne odstępy RGB</h2>

<div id="controls">
  <button id="startBtn">Start kamery</button>

  <label>Skala wyjścia:
    <select id="scale">
      <option value="2">2×</option>
      <option value="3" selected>3×</option>
      <option value="4">4×</option>
    </select>
  </label>

  <label>Próg: <span id="thVal">20</span>
    <input id="threshold" type="range" min="0" max="255" value="20" />
  </label>

  <label><input id="blur" type="checkbox" /> prosty 3×3 blur</label>

  <div>
    <label>Odstępy kanałów (JSON):</label><br>
    <textarea id="rgbConfig">{ "R": 2, "G": 3, "B": 4 }</textarea>
    <small class="muted">Edytuj przed uruchomieniem kamery. Każdy kanał oznacza odstęp w klatkach od bieżącej.</small>
  </div>
</div>

<canvas id="out" width="128" height="128" style="width:384px;height:384px"></canvas>
<small class="muted">Porównania dla R,G,B tworzą kolory w zależności od odstępów między klatkami.</small>

<canvas id="small" width="128" height="128" style="display:none"></canvas>
<video id="video" autoplay playsinline style="display:none"></video>

<script>
(() => {
  const W = 128, H = 128;
  const video = document.getElementById('video');
  const small = document.getElementById('small');
  const out = document.getElementById('out');
  const startBtn = document.getElementById('startBtn');
  const thresholdEl = document.getElementById('threshold');
  const thVal = document.getElementById('thVal');
  const blurChk = document.getElementById('blur');
  const scaleSel = document.getElementById('scale');
  const rgbConfigEl = document.getElementById('rgbConfig');

  const sctx = small.getContext('2d', {willReadFrequently:true});
  const octx = out.getContext('2d');

  let running = false;
  let grayHistory = [];
  let rgbGaps = { R:2, G:3, B:4 };

  function updateOutputSize() {
    const scale = Number(scaleSel.value);
    out.style.width = (W * scale) + 'px';
    out.style.height = (H * scale) + 'px';
  }
  scaleSel.addEventListener('change', updateOutputSize);
  updateOutputSize();

  thresholdEl.addEventListener('input', () => thVal.textContent = thresholdEl.value);

  async function startCamera() {
    try {
      try {
        rgbGaps = JSON.parse(rgbConfigEl.value);
      } catch (err) {
        alert("Błąd w JSON — używam domyślnego {R:2,G:3,B:4}");
        rgbGaps = {R:2,G:3,B:4};
      }

      const stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode:"environment" }, audio:false });
      video.srcObject = stream;
      await video.play();
      running = true;
      startBtn.textContent = 'Stop';
      grayHistory = [];
      requestAnimationFrame(loop);
    } catch(e) {
      alert('Błąd uruchomienia kamery: ' + e.message);
      console.error(e);
    }
  }

  function stopCamera() {
    if (video.srcObject) {
      video.srcObject.getTracks().forEach(t => t.stop());
      video.srcObject = null;
    }
    running = false;
    startBtn.textContent = 'Start kamery';
    grayHistory = [];
    octx.clearRect(0,0,out.width,out.height);
  }

  startBtn.addEventListener('click', () => {
    if (!running) startCamera();
    else stopCamera();
  });

  function rgbToGray(r,g,b){ return (0.299*r + 0.587*g + 0.114*b)|0; }

  function boxBlur3x3(src,dst,w,h){
    const get=(x,y)=>src[Math.min(h-1,Math.max(0,y))*w+Math.min(w-1,Math.max(0,x))];
    for(let y=0;y<h;y++){
      for(let x=0;x<w;x++){
        let s=0;
        for(let dy=-1;dy<=1;dy++)
          for(let dx=-1;dx<=1;dx++)
            s+=get(x+dx,y+dy);
        dst[y*w+x]=(s/9)|0;
      }
    }
  }

  const tempBlur = new Uint8ClampedArray(W*H);

  function loop() {
    if (!running) return;
    sctx.drawImage(video,0,0,W,H);
    const img = sctx.getImageData(0,0,W,H);
    const data = img.data;
    const gray = new Uint8ClampedArray(W*H);
    for (let i=0,j=0;i<data.length;i+=4,j++) gray[j]=rgbToGray(data[i],data[i+1],data[i+2]);

    if (blurChk.checked){ boxBlur3x3(gray,tempBlur,W,H); gray.set(tempBlur); }

    grayHistory.push(gray);
    const maxGap = Math.max(rgbGaps.R,rgbGaps.G,rgbGaps.B);
    if (grayHistory.length > maxGap + 1) grayHistory.shift();

    if (grayHistory.length > maxGap) {
      const outImg = octx.createImageData(W,H);
      const outBuf = outImg.data;
      const th = Number(thresholdEl.value);

      for (let i=0,p=0;i<gray.length;i++,p+=4) {
        const rDiff = Math.abs(gray[i] - grayHistory[grayHistory.length - 1 - rgbGaps.R][i]);
        const gDiff = Math.abs(gray[i] - grayHistory[grayHistory.length - 1 - rgbGaps.G][i]);
        const bDiff = Math.abs(gray[i] - grayHistory[grayHistory.length - 1 - rgbGaps.B][i]);
        outBuf[p]   = rDiff > th ? rDiff : 0;
        outBuf[p+1] = gDiff > th ? gDiff : 0;
        outBuf[p+2] = bDiff > th ? bDiff : 0;
        outBuf[p+3] = 255;
      }
      octx.putImageData(outImg,0,0);
    }

    requestAnimationFrame(loop);
  }

  window.addEventListener('unload', stopCamera);
})();
</script>
</body>
</html>
